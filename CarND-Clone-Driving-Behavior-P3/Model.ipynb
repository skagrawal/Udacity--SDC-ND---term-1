{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from numpy import newaxis\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU,Activation,MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from numpy import random\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import json\n",
    "import os\n",
    "import h5py\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading CSV file for image and steering angle details\n",
    "file_name = 'driving_log.csv'\n",
    "# data = read_data(file_name)\n",
    "# data = pd.DataFrame(data)\n",
    "# data\n",
    "\n",
    "data = pd.read_csv(file_name)\n",
    "# data = data[0:100][:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop the image to remove portion containing useless information like hood of car or top part of trees\n",
    "def resize_image(image):\n",
    "    shape = image.shape\n",
    "    image = image[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]]\n",
    "    image1 = cv2.resize(image,(new_col, new_row),interpolation=cv2.INTER_AREA)    \n",
    "    return image1\n",
    "\n",
    "\n",
    "# Adding brightness to incorporate different level of available light situation while capturing pics\n",
    "def add_random_brightness(image, rand_val=.25+np.random.uniform()):\n",
    "    image_tran = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image_tran[:,:,2] = image_tran[:,:,2]*rand_val\n",
    "    return cv2.cvtColor(image_tran,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "\n",
    "# Function to randmly flip the image and reverse the angle\n",
    "def flip_image(image,y_steer):\n",
    "    if np.random.randint(2) == 0:\n",
    "        image = cv2.flip(image,1)\n",
    "        y_steer = -y_steer\n",
    "    return image,y_steer\n",
    "\n",
    "# Randomly selecting one of the three images and applying different preprocessing before using it for modeling\n",
    "def preprocess_image(line):\n",
    "    i = np.random.randint(3)\n",
    "    if (i == 0):\n",
    "        file = line['center'][0].strip()\n",
    "        shift_ang = 0.0\n",
    "    if (i == 1):\n",
    "        file = line['left'][0].strip()\n",
    "        shift_ang = 0.25        \n",
    "    if (i == 2):\n",
    "        file = line['right'][0].strip()\n",
    "        shift_ang = -0.25\n",
    "    y = line['steering'][0] + shift_ang\n",
    "    image = cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2RGB)\n",
    "    image = add_random_brightness(image,.25+np.random.uniform())\n",
    "    image = np.array(resize_image(image))\n",
    "    return flip_image(image,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Batch Generator function for training\n",
    "def generate_train(data,batch_size = 128):\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    batch_images = np.zeros((batch_size, new_col, new_row, 3))\n",
    "    \n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i = np.random.randint(len(data))\n",
    "            line = data.iloc[[i]].reset_index()\n",
    "            x,y = preprocess_image(line)\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering\n",
    "        \n",
    "# Batch Generator function for validation\n",
    "def generate_validate(data):\n",
    "    while 1:\n",
    "        for i in range(len(data)):\n",
    "            line = data.iloc[[i]].reset_index()\n",
    "            image = cv2.imread(line['center'][0].strip())\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            image = np.array(resize_image(image))\n",
    "            x = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "            y = np.array([[line['steering'][0]]])\n",
    "            yield x, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for i_batch in range(10):\n",
    "    i = np.random.randint(len(data))\n",
    "    line = data.iloc[[i]].reset_index()\n",
    "    x,y = preprocess_image(line)\n",
    "#     plt.imshow(x)\n",
    "    plt.subplot(2,5,i_batch+1)\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load or define model\n",
    "try:\n",
    "    with open('model.json', 'r') as model_json:\n",
    "        model = model_from_json(json.load(model_json))\n",
    "\n",
    "    # Use adam optimizer and mean squared error for compiling the model\n",
    "    model.compile(\"adam\", \"mse\")\n",
    "\n",
    "    # import weights\n",
    "    model.load_weights('model.h5')\n",
    "\n",
    "    print(\"Imported model and weights\")\n",
    "\n",
    "\n",
    "except:\n",
    "    # New dimension of images\n",
    "    new_col,new_row = 64, 64\n",
    "    # Drop out layer prob\n",
    "    drop_prob = 0.5\n",
    "    # New dimension of input\n",
    "    input_shape = (new_col, new_row, 3)\n",
    "    # Filter size for Convolution\n",
    "    filter_size = 3\n",
    "    # Pool size for Max pooling\n",
    "    pool_size = (2,2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/255.-0.5,input_shape=input_shape))\n",
    "\n",
    "    model.add(Convolution2D(3,1,1,border_mode='valid', name='conv0', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Convolution2D(24,filter_size,filter_size, border_mode='valid',name='conv1', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Convolution2D(48,filter_size,filter_size,border_mode='valid',name='conv2', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Convolution2D(64,filter_size,filter_size,border_mode='valid',name='conv3', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "\n",
    "    model.add(Convolution2D(128,filter_size,filter_size, border_mode='valid', name='conv4', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512,name='conn1', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(drop_prob))\n",
    "    model.add(Dense(128,name='conn2', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(drop_prob))\n",
    "    model.add(Dense(64,name='conn3', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(drop_prob))\n",
    "    model.add(Dense(16,name='conn4',init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(drop_prob))\n",
    "    # Final output layer \n",
    "    model.add(Dense(1, name='output', init='he_normal'))\n",
    "    \n",
    "    # Print model summary\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compile model using Adam optimizer\n",
    "model.compile(\"adam\", \"mse\")\n",
    "# New size of images\n",
    "new_col, new_row = 64, 64\n",
    "# Batch size to be processed\n",
    "batch_size = 256\n",
    "# Validation set size\n",
    "val_size = 1000\n",
    "\n",
    "# Training model here using fit_generator to save memory by not loading all images at same time\n",
    "history = model.fit_generator(generate_train(data,batch_size),nb_epoch=50,\n",
    "            samples_per_epoch=batch_size*200, validation_data=generate_validate(data),\n",
    "                        nb_val_samples=val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if 'model.json' in os.listdir():\n",
    "    print(\"the model already exists\")\n",
    "else:\n",
    "    # Save model as json file\n",
    "    json_string = model.to_json()\n",
    "    with open('model.json', 'w') as outfile:\n",
    "        json.dump(json_string, outfile)\n",
    "\n",
    "    # save model weights\n",
    "    model.save_weights('./model.h5')\n",
    "    print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
